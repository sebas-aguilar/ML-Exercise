{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# Read in the data, note: 'education-num' is a proxy for number of years in education\n",
    "dataTypes = {'age':np.uint8,'workclass':'category', 'fnlwgt':np.uint32, 'education':'category', 'education-num':np.uint8,\n",
    "             'marital-status':'category', 'occupation':'category', 'relationship':'category', 'race':'category', 'sex':'category', \n",
    "             'capital-gain':np.uint32, 'capital-loss':np.uint32, 'hours-per-week':np.uint8, 'native-country':'category',\n",
    "             'class':'category'}\n",
    "\n",
    "# Note, we have a mixture of categorical and numerical data\n",
    "X_train = pd.read_csv('trainingData/au_train.csv', dtype=dataTypes, skipinitialspace=True, engine='c')\n",
    "y_train = X_train['class'].to_numpy()\n",
    "X_train.drop(columns=['class'],inplace=True)\n",
    "print(X_train.info())\n",
    "# print(y_train.info())\n",
    "# print(X_train.isnull().sum())\n",
    "# print(X_train.isna().sum())\n",
    "\n",
    "\n",
    "X_test = pd.read_csv('testingData/au_test.csv', dtype=dataTypes, skipinitialspace=True ,engine='c')\n",
    "y_test = X_test['class'].to_numpy()\n",
    "X_test.drop(columns=['class'],inplace=True)\n",
    "# print(X_test.info())\n",
    "# print(y_test.info())\n",
    "# print(X_test.isnull().sum())\n",
    "# print(X_test.isna().sum())\n",
    "\n",
    "\n",
    "# Check for unlabeled categorical features in X_train\n",
    "# print(sorted(list(X_train['workclass'].unique())))\n",
    "# print(sorted(list(X_train['occupation'].unique())))\n",
    "print(sorted(list(X_train['native-country'].unique())))\n",
    "\n",
    "# Check for unlabeled target (binary) in y_train (ITS GOOD)\n",
    "# print(list(y_train['class'].unique()))\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "# Check for unlabeled categorical features in X_test\n",
    "# print(sorted(list(X_test['workclass'].unique())))\n",
    "# print(sorted(list(X_test['occupation'].unique())))\n",
    "print(sorted(list(X_test['native-country'].unique())))\n",
    "\n",
    "# Check for unlabeled target (binary) in y_test (ITS GOOD)\n",
    "# print(list(y_train['class'].unique()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have heterogeneous data (mixed numerical and categorical data), *scikit-learn* requires explicit conversion of categorical features to numeric values (**preprocessing**).\n",
    "1. Possibility to scale the numeric features (helpful sometimes)\n",
    "2. Categorical data will be *encoded*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "\n",
    "# Create the preprocessing pipelines for categorical data of training set.\n",
    "train_categorical_features = [catFeat for catFeat in X_train.select_dtypes(include=\"category\")]\n",
    "enc = OrdinalEncoder(categories='auto')\n",
    "enc.fit(X_train[train_categorical_features[:]])\n",
    "X_train[train_categorical_features[:]] = enc.transform(X_train[train_categorical_features[:]])\n",
    "\n",
    "# Create the preprocessing pipelines for categorical data of test set.\n",
    "test_categorical_features = [catFeat for catFeat in X_test.select_dtypes(include=\"category\")]\n",
    "enc = OrdinalEncoder(categories='auto')\n",
    "enc.fit(X_test[test_categorical_features[:]])\n",
    "X_test[test_categorical_features[:]] = enc.transform(X_test[test_categorical_features[:]])\n",
    "\n",
    "# Plot correlation matrix\n",
    "corr = X_train.corr()\n",
    "labelNames = list(X_train.columns.values)\n",
    "\n",
    "im = plt.matshow(corr,cmap='viridis',interpolation='bilinear')\n",
    "plt.xticks(np.arange(corr.shape[1]),labels=labelNames,rotation=45,va='bottom',ha='left')\n",
    "plt.yticks(np.arange(corr.shape[0]),labels=labelNames)\n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data has been preprocessed, lets play with some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=50000,  random_state=np.random.RandomState())\n",
    "sgd_clf.fit(X_train,y_train)\n",
    "sgd_pred = sgd_clf.predict(X_test)\n",
    "print('SGD score:',sgd_clf.score(X_test,y_test))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(sgd_clf, X_train, y_train, cv=3,scoring='accuracy'))\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "svm_clf = svm.SVC()\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_pred = svm_clf.predict(X_test)\n",
    "print('SVM score:',svm_clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The DataFrames 'class' column is non-numeric, append a new column 'class-num' to serve as a numerical proxy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData['class-num'] = trainingData['class'].apply(lambda x: 0 if x == '<=50K' else( 1 if x == '>50K' else -1))\n",
    "testingData['class-num'] = testingData['class'].apply(lambda x: 0 if x == '<=50K' else( 1 if x == '>50K' else -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try 'groupby' method and see if we can establish some patterns\n",
    "## sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupbySex = trainingData.groupby('sex')\n",
    "colorDict = {'Male':'b','Female':'r'}\n",
    "for sex,group in groupbySex:\n",
    "#     print(sex)\n",
    "#     print(group.describe(),'\\n\\n')\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
    "    fig.patch.set_facecolor('xkcd:gray')\n",
    "    fig.suptitle(sex)\n",
    "    group.plot.scatter(ax=axes[0,0],x='education-num', y='capital-gain', c=colorDict[str(sex)], label=sex, legend=True, alpha=.1)\n",
    "    group.plot.hexbin(ax=axes[0,1],x='education-num', y='capital-gain', gridsize=15,cmap='viridis',norm=LogNorm())\n",
    "    group.plot.scatter(ax=axes[1,1],x='education-num', y='capital-gain', s=group['hours-per-week']*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupRace = trainingData.groupby('race')\n",
    "for race,group in groupRace:\n",
    "    print(race)\n",
    "    print(group.describe(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## education-num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupEdu = trainingData.groupby('education-num')\n",
    "for edu,group in groupEdu:\n",
    "    print(edu)\n",
    "    print(group.describe(),'\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
